{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "tictactoe.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a13uhqunn6lI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copied from https://github.com/neilslater/game_playing_scripts\n",
        "\n",
        "'''\n",
        "   Copyright 2017 Neil Slater\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "from itertools import groupby\n",
        "\n",
        "class TicTacToeGame():\n",
        "    def __init__(self):\n",
        "        self.state = '         '\n",
        "        self.player = 'X'\n",
        "        self.winner = None\n",
        "\n",
        "    def allowed_moves(self):\n",
        "        states = []\n",
        "        for i in range(len(self.state)):\n",
        "            if self.state[i] == ' ':\n",
        "                states.append(self.state[:i] + self.player + self.state[i+1:])\n",
        "        return states\n",
        "\n",
        "    def make_move(self, next_state):\n",
        "        if self.winner:\n",
        "            raise(Exception(\"Game already completed, cannot make another move!\"))\n",
        "        if not self.__valid_move(next_state):\n",
        "            raise(Exception(\"Cannot make move {} to {} for player {}\".format(\n",
        "                    self.state, next_state, self.player)))\n",
        "\n",
        "        self.state = next_state\n",
        "        self.winner = self.predict_winner(self.state)\n",
        "        if self.winner:\n",
        "            self.player = None\n",
        "        elif self.player == 'X':\n",
        "            self.player = 'O'\n",
        "        else:\n",
        "            self.player = 'X'\n",
        "\n",
        "    def playable(self):\n",
        "        return ( (not self.winner) and any(self.allowed_moves()) )\n",
        "\n",
        "    def predict_winner(self, state):\n",
        "        lines = [(0,1,2), (3,4,5), (6,7,8), (0,3,6), (1,4,7), (2,5,8), (0,4,8), (2,4,6)]\n",
        "        winner = None\n",
        "        for line in lines:\n",
        "            line_state = state[line[0]] + state[line[1]] + state[line[2]]\n",
        "            if line_state == 'XXX':\n",
        "                winner = 'X'\n",
        "            elif line_state == 'OOO':\n",
        "                winner = 'O'\n",
        "        return winner\n",
        "\n",
        "    def __valid_move(self, next_state):\n",
        "        allowed_moves = self.allowed_moves()\n",
        "        if any(state == next_state for state in allowed_moves):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def print_board(self):\n",
        "        s = self.state\n",
        "        print('     {} | {} | {} '.format(s[0],s[1],s[2]))\n",
        "        print('    -----------')\n",
        "        print('     {} | {} | {} '.format(s[3],s[4],s[5]))\n",
        "        print('    -----------')\n",
        "        print('     {} | {} | {} '.format(s[6],s[7],s[8]))\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt8vRmMVP2z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPrjAayVPtlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, lr=0.00001):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(18, 24)\n",
        "        self.fc2 = nn.Linear(24, 1)\n",
        "\n",
        "        self.fc1.weight.data.fill_(0.0)\n",
        "        self.fc2.weight.data.fill_(0.0)\n",
        "        \n",
        "        self.optim = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "        self.loss = F.torch.nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScUaE0Zvn6lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, game_class, epsilon=0.1, alpha=1.0, player_mark='X'):\n",
        "        self.alpha = alpha\n",
        "        self.model = Net()\n",
        "        self.NewGame = game_class\n",
        "        self.epsilon = epsilon\n",
        "        self.player_mark = player_mark\n",
        "\n",
        "    def state_value(self, game_state, V):\n",
        "        return V.get(game_state, 0.0)\n",
        "        \n",
        "    def learn_game(self, num_episodes=1000):\n",
        "        teach_data = []\n",
        "        batch_size = 100\n",
        "        for episode in range(num_episodes):\n",
        "            teach_data.extend(self.learn_from_episode())\n",
        "            if (episode % batch_size) == 0 and episode > 0:\n",
        "                for data in teach_data:\n",
        "                    self.teach_nn(data)\n",
        "                teach_data.clear()\n",
        "\n",
        "    def learn_from_episode(self):\n",
        "        game = self.NewGame()\n",
        "        prev_state = game.state\n",
        "        V = dict()\n",
        "        _, move = self.learn_select_move(game, V)\n",
        "        teach_data = []\n",
        "        while move:\n",
        "            prev_state = move\n",
        "            move = self.learn_from_move(game, move, V)\n",
        "            teach_data.append({'state' : prev_state, 'action' : move, 'value' : self.state_value(move, V)})\n",
        "        return teach_data\n",
        "\n",
        "    def teach_nn(self, data):\n",
        "        x = self.__tensor_from_states(data['state'], data['action'])\n",
        "        y = data['value']\n",
        "        y_pred = self.model(x)\n",
        "        loss = self.model.loss(y_pred, torch.tensor([y]))\n",
        "        self.model.optim.zero_grad()\n",
        "        loss.backward()\n",
        "        self.model.optim.step()\n",
        "        \n",
        "    def learn_from_move(self, game, move, V):\n",
        "        game.make_move(move)\n",
        "        r = self.__reward(game)\n",
        "        next_state_value = 0.0\n",
        "        selected_next_move = None\n",
        "        if game.playable():\n",
        "            best_next_move, selected_next_move = self.learn_select_move(game, V)\n",
        "            next_state_value = self.state_value(best_next_move, V)\n",
        "        current_state_value = self.state_value(move, V)\n",
        "        td_target = r + next_state_value\n",
        "        V[move] = current_state_value + self.alpha * (td_target - current_state_value)\n",
        "        \n",
        "        return selected_next_move\n",
        "\n",
        "    def learn_select_move(self, game, V):\n",
        "        allowed_state_values = self.__state_values(game.allowed_moves(), V)\n",
        "        if game.player == self.player_mark:\n",
        "            best_move = self.__argmax_V(allowed_state_values)\n",
        "        else:\n",
        "            best_move = self.__argmin_V(allowed_state_values)\n",
        "\n",
        "        selected_move = best_move\n",
        "        if random.random() < self.epsilon:\n",
        "            selected_move = self.__random_V(allowed_state_values)\n",
        "\n",
        "        return (best_move, selected_move)\n",
        "\n",
        "    def play_select_move(self, game):\n",
        "        allowed_state_values = self.__predict_state_values(game.state, game.allowed_moves())\n",
        "        if game.player == self.player_mark:\n",
        "            return self.__argmax_V(allowed_state_values)\n",
        "        else:\n",
        "            return self.__argmin_V(allowed_state_values)\n",
        "\n",
        "    def demo_game(self, verbose=False):\n",
        "        game = self.NewGame()\n",
        "        t = 0\n",
        "        while game.playable():\n",
        "            if verbose:\n",
        "                print(\" \\nTurn {}\\n\".format(t))\n",
        "                game.print_board()\n",
        "            move = self.play_select_move(game)\n",
        "            game.make_move(move)\n",
        "            t += 1\n",
        "        if verbose:\n",
        "            print(\" \\nTurn {}\\n\".format(t))\n",
        "            game.print_board()\n",
        "        if game.winner:\n",
        "            if verbose:\n",
        "                print(\"\\n{} is the winner!\".format(game.winner))\n",
        "            return game.winner\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(\"\\nIt's a draw!\")\n",
        "            return '-'\n",
        "\n",
        "    def interactive_game(self, agent_player='X'):\n",
        "        game = self.NewGame()\n",
        "        t = 0\n",
        "        while game.playable():\n",
        "            print(\" \\nTurn {}\\n\".format(t))\n",
        "            game.print_board()\n",
        "            if game.player == agent_player:\n",
        "                move = self.play_select_move(game)\n",
        "                game.make_move(move)\n",
        "            else:\n",
        "                move = self.__request_human_move(game)\n",
        "                game.make_move(move)\n",
        "            t += 1\n",
        "\n",
        "        print(\" \\nTurn {}\\n\".format(t))\n",
        "        game.print_board()\n",
        "\n",
        "        if game.winner:\n",
        "            print(\"\\n{} is the winner!\".format(game.winner))\n",
        "            return game.winner\n",
        "        print(\"\\nIt's a draw!\")\n",
        "        return '-'\n",
        "\n",
        "    def __tensor_from_states(self, cur_state, state):    \n",
        "        state_tensor = []\n",
        "        def append_state(s):\n",
        "            if s is None:\n",
        "                for i in range(9):\n",
        "                    state_tensor.append(0.0)\n",
        "            else:\n",
        "                for sym in s:\n",
        "                    if sym == ' ':\n",
        "                        state_tensor.append(0.0)\n",
        "                    elif sym == 'X':\n",
        "                        state_tensor.append(1.0)\n",
        "                    elif sym == 'O':\n",
        "                        state_tensor.append(-1.0)\n",
        "                    else:\n",
        "                        assert False, \"Incorrect sym\"\n",
        "        append_state(cur_state)\n",
        "        append_state(state)\n",
        "\n",
        "        return torch.tensor(state_tensor)\n",
        "\n",
        "    def __predict_state_values(self, cur_state, game_states):\n",
        "        return dict((state, self.model(self.__tensor_from_states(cur_state, state))) for state in game_states)\n",
        "\n",
        "    def __state_values(self, game_states, V):\n",
        "        return dict((state, self.state_value(state, V)) for state in game_states)\n",
        "\n",
        "    def __argmax_V(self, state_values):\n",
        "        max_V = max(state_values.values())\n",
        "        chosen_state = random.choice([state for state, v in state_values.items() if v == max_V])\n",
        "        return chosen_state\n",
        "\n",
        "    def __argmin_V(self, state_values):\n",
        "        min_V = min(state_values.values())\n",
        "        chosen_state = random.choice([state for state, v in state_values.items() if v == min_V])\n",
        "        return chosen_state\n",
        "\n",
        "    def __random_V(self, state_values):\n",
        "        return random.choice(list(state_values.keys()))\n",
        "\n",
        "    def __reward(self, game):\n",
        "        if game.winner == self.player_mark:\n",
        "            return 1.0\n",
        "        elif game.winner:\n",
        "            return -1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def __request_human_move(self, game):\n",
        "        allowed_moves = [i+1 for i in range(9) if game.state[i] == ' ']\n",
        "        human_move = None\n",
        "        while not human_move:\n",
        "            idx = int(input('Choose move for {}, from {} : '.format(game.player, allowed_moves)))\n",
        "            if any([i==idx for i in allowed_moves]):\n",
        "                human_move = game.state[:idx-1] + game.player + game.state[idx:]\n",
        "        return human_move"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LWBMtion6lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def demo_game_stats(agent):\n",
        "    results = [agent.demo_game() for i in range(10000)]\n",
        "    game_stats = {k: results.count(k)/100 for k in ['X', 'O', '-']}\n",
        "    print(\"    percentage results: {}\".format(game_stats))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRvctiyPn6lR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "46a82b0c-cdd1-4f67-cde4-3d04171e5819"
      },
      "source": [
        "agent = Agent(TicTacToeGame, epsilon = 0.1, alpha = 1.0)\n",
        "print(\"Before learning:\")\n",
        "demo_game_stats(agent)\n",
        "\n",
        "agent.learn_game(1000)\n",
        "print(\"After 1000 learning games:\")\n",
        "demo_game_stats(agent)\n",
        "\n",
        "agent.learn_game(4000)\n",
        "print(\"After 5000 learning games:\")\n",
        "demo_game_stats(agent)\n",
        "\n",
        "agent.learn_game(5000)\n",
        "print(\"After 10000 learning games:\")\n",
        "demo_game_stats(agent)\n",
        "\n",
        "agent.learn_game(10000)\n",
        "print(\"After 20000 learning games:\")\n",
        "demo_game_stats(agent)\n",
        "\n",
        "agent.learn_game(10000)\n",
        "print(\"After 30000 learning games:\")\n",
        "demo_game_stats(agent)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before learning:\n",
            "    percentage results: {'X': 58.78, 'O': 28.47, '-': 12.75}\n",
            "After 1000 learning games:\n",
            "    percentage results: {'X': 59.61, 'O': 27.55, '-': 12.84}\n",
            "After 5000 learning games:\n",
            "    percentage results: {'X': 75.06, 'O': 0.0, '-': 24.94}\n",
            "After 10000 learning games:\n",
            "    percentage results: {'X': 49.43, 'O': 50.57, '-': 0.0}\n",
            "After 20000 learning games:\n",
            "    percentage results: {'X': 0.0, 'O': 0.0, '-': 100.0}\n",
            "After 30000 learning games:\n",
            "    percentage results: {'X': 0.0, 'O': 0.0, '-': 100.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpdXVgH-n6lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30dbc648-ce9e-4325-eb7d-79200c214a3a"
      },
      "source": [
        "agent.demo_game(True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            "Turn 0\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "       |   |   \n",
            "    -----------\n",
            "       |   |   \n",
            " \n",
            "Turn 1\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "     X |   |   \n",
            "    -----------\n",
            "       |   |   \n",
            " \n",
            "Turn 2\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "     X |   |   \n",
            "    -----------\n",
            "     O |   |   \n",
            " \n",
            "Turn 3\n",
            "\n",
            "       |   |   \n",
            "    -----------\n",
            "     X |   |   \n",
            "    -----------\n",
            "     O |   | X \n",
            " \n",
            "Turn 4\n",
            "\n",
            "     O |   |   \n",
            "    -----------\n",
            "     X |   |   \n",
            "    -----------\n",
            "     O |   | X \n",
            " \n",
            "Turn 5\n",
            "\n",
            "     O |   |   \n",
            "    -----------\n",
            "     X | X |   \n",
            "    -----------\n",
            "     O |   | X \n",
            " \n",
            "Turn 6\n",
            "\n",
            "     O |   |   \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O |   | X \n",
            " \n",
            "Turn 7\n",
            "\n",
            "     O |   | X \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O |   | X \n",
            " \n",
            "Turn 8\n",
            "\n",
            "     O |   | X \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O | O | X \n",
            " \n",
            "Turn 9\n",
            "\n",
            "     O | X | X \n",
            "    -----------\n",
            "     X | X | O \n",
            "    -----------\n",
            "     O | O | X \n",
            "\n",
            "It's a draw!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'-'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpV2rMXCn6lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}