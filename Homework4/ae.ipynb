{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "ae.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3WekG2xmxI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O62EnHlCOxFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,)),\n",
        "           ])\n",
        "\n",
        "def mnist(batch_size=50, valid=0, shuffle=True, transform=mnist_transform, path='./MNIST_data'):\n",
        "    test_data = datasets.MNIST(path, train=False, download=True, transform=transform)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    train_data = datasets.MNIST(path, train=True, download=True, transform=transform)\n",
        "    if valid > 0:\n",
        "        num_train = len(train_data)\n",
        "        indices = list(range(num_train))\n",
        "        split = num_train-valid\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        train_idx, valid_idx = indices[:split], indices[split:]\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
        "        valid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
        "    \n",
        "        return train_loader, valid_loader, test_loader\n",
        "    else:\n",
        "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
        "        return train_loader, test_loader\n",
        "\n",
        "\n",
        "def plot_mnist(images, shape):\n",
        "    fig = plt.figure(figsize=shape[::-1], dpi=80)\n",
        "    for j in range(1, len(images) + 1):\n",
        "        ax = fig.add_subplot(shape[0], shape[1], j)\n",
        "        ax.matshow(images[j - 1, 0, :, :], cmap = matplotlib.cm.binary)\n",
        "        plt.xticks(np.array([]))\n",
        "        plt.yticks(np.array([]))\n",
        "    plt.show()\n",
        "    \n",
        "def plot_graphs(log, tpe='loss'):\n",
        "    keys = log.keys()\n",
        "    logs = {k:[z for z in zip(*log[k])] for k in keys}\n",
        "    epochs = {k:range(len(log[k])) for k in keys}\n",
        "    \n",
        "    if tpe == 'loss':\n",
        "        handlers, = zip(*[plt.plot(epochs[k], logs[k][0], label=k) for k in keys])\n",
        "        plt.title('errors')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('error')\n",
        "        plt.legend(handles=handlers)\n",
        "        plt.show()\n",
        "    elif tpe == 'accuracy':\n",
        "        handlers, = zip(*[plt.plot(epochs[k], logs[k][1], label=k) for k in log.keys()])\n",
        "        plt.title('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.legend(handles=handlers)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNI39V-mmxJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,), (0.5,)),\n",
        "           ])\n",
        "\n",
        "train_loader, test_loader = mnist(batch_size=200, valid=0, transform=mnist_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY7Wv9symxJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_size=10):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, latent_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_size=10):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_size, 28*28)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-AxOrBdmxJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, latent_size=10, loss_fn=F.mse_loss, lr=1e-4, l2=0.):\n",
        "        super(Net, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.E = Encoder(latent_size)\n",
        "        self.D = Decoder(latent_size)\n",
        "        self.loss_fn = loss_fn\n",
        "        self._loss = None\n",
        "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        h = self.E(x)\n",
        "        out = self.D(h)\n",
        "        return out\n",
        "    \n",
        "    def decode(self, h):\n",
        "        with torch.no_grad():\n",
        "            return self.D(h)\n",
        "    \n",
        "    def loss(self, x, target, **kwargs):\n",
        "        target = target.view(-1, 28*28)\n",
        "        self._loss = self.loss_fn(x, target, **kwargs)\n",
        "        return self._loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTGrm2BfmxJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {2: Net(2), 32: Net(32)}\n",
        "train_log = {k: [] for k in models}\n",
        "test_log = {k: [] for k in models}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdLwAm_LmxJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, models, log=None):\n",
        "    train_size = len(train_loader.sampler)\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        for model in models.values():\n",
        "            model.optim.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = model.loss(output, data)\n",
        "            loss.backward()\n",
        "            model.optim.step()\n",
        "            \n",
        "        if batch_idx % 150 == 0:\n",
        "            line = 'Train Epoch: {} [{:05d}/{}] '.format(\n",
        "                epoch, batch_idx * len(data), train_size)\n",
        "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
        "            print(line + losses)\n",
        "            \n",
        "    else:\n",
        "        batch_idx += 1\n",
        "        line = 'Train Epoch: {} [{:05d}/{}] '.format(\n",
        "            epoch, batch_idx * len(data), train_size)\n",
        "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
        "        if log is not None:\n",
        "            for k in models:\n",
        "                log[k].append(models[k]._loss)\n",
        "        print(line + losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpDMAVomxJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_lambda = lambda l: 'loss: {:.4f}'.format(l)\n",
        "line = lambda i, l: '{}: '.format(i) + avg_lambda(l)\n",
        "    \n",
        "def test(models, loader, log=None):\n",
        "    test_size = len(loader.sampler)\n",
        "\n",
        "    test_loss = {k: 0. for k in models}\n",
        "    with torch.no_grad():\n",
        "        for data, _ in loader:\n",
        "            output = {k: m(data) for k, m in models.items()}\n",
        "            for k, m in models.items():\n",
        "                test_loss[k] += m.loss(output[k], data, reduction='sum').item() # sum up batch loss\n",
        "    \n",
        "    for k in models:\n",
        "        test_loss[k] /= (test_size * 784)\n",
        "        if log is not None:\n",
        "            log[k].append(test_loss[k])\n",
        "    \n",
        "    lines = '\\n'.join([line(k, test_loss[k]) for k in models]) + '\\n'\n",
        "    report = 'Test set:\\n' + lines        \n",
        "    print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6tdngxUmxJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(1, 31):\n",
        "    for model in models.values():\n",
        "        model.train()\n",
        "    train(epoch, models, train_log)\n",
        "    for model in models.values():\n",
        "        model.eval()\n",
        "    test(models, test_loader, test_log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdK58233mxJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import *\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "x = linspace(0, 1, 10)\n",
        "\n",
        "results = []\n",
        "for data, _ in train_loader:\n",
        "  data = data.reshape(-1,28*28)\n",
        "  results.append(models[2].E(data))\n",
        "\n",
        "plt.scatter(results[0].detach().numpy(), results[1].detach().numpy(), s=1, c='black')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PRrq39WmxJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, perplexity=30.0)\n",
        "\n",
        "for data, y in train_loader:\n",
        "  data = data.reshape(-1,28*28)\n",
        "  result = models[32].E(data)\n",
        "  tsne_transformed = tsne.fit_transform(result.cpu().detach().numpy())\n",
        "\n",
        "  plt.scatter(tsne_transformed[:,0], tsne_transformed[:,1], c=y)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVDa5WrmxJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}